# ğŸ‡¸ğŸ‡¦ Absher Hackathon - Aoun AI Assistant

<div align="center">

![Absher Logo](./absher_logo.svg)

**Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©**

[![Next.js](https://img.shields.io/badge/Next.js-15-black?style=for-the-badge&logo=next.js)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Python-green?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-CSS-38B2AC?style=for-the-badge&logo=tailwind-css)](https://tailwindcss.com/)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Environment Variables](#-environment-variables)
- [Usage](#-usage)
- [Voice Agent](#-voice-agent)
- [API Documentation](#-api-documentation)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸŒŸ Overview

**Ø¹ÙˆÙ† (Aoun)** is an intelligent AI assistant developed for the Saudi Arabian government's Absher platform. It provides citizens with seamless access to government services through text chat and voice interactions.

### ğŸ¯ Key Capabilities:
- ğŸ¤– **AI-Powered Chat**: Natural language understanding using Groq LLaMA 3.3
- ğŸ¤ **Voice Agent**: Full voice interaction with TTS (ElevenLabs) & STT (OpenAI Whisper)
- ğŸ“Š **Service Integration**: Check violations, manage documents, handle life events
- ğŸ‡¸ğŸ‡¦ **Arabic-First**: Fully optimized for Arabic language and RTL layout

---

## âœ¨ Features

### ğŸ—£ï¸ Voice Agent (Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© Ø§Ù„ØµÙˆØªÙŠØ©)
- âœ… **Text-to-Speech (TTS)**: ElevenLabs API with Arabic multilingual voice
- âœ… **Speech-to-Text (STT)**: OpenAI Whisper for accurate Arabic transcription
- âœ… **Voice Activity Detection (VAD)**: Automatic silence detection
- âœ… **Auto-Stop on Silence**: Stops recording after 1 second of silence
- âœ… **Conversation Loop**: Continuous back-and-forth interaction
- âœ… **Echo Cancellation**: Enhanced audio processing

### ğŸ’¬ Chat Interface (Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©)
- âœ… **Real AI Responses**: Powered by Groq LLaMA 3.3 (70B parameters)
- âœ… **Context Awareness**: Maintains conversation history
- âœ… **Data Integration**: Access to violations, documents, vehicles
- âœ… **Quick Actions**: Pay fines, submit appeals, request services

### ğŸ“¦ Life Event Bundles (Ø­Ø²Ù… Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø­ÙŠØ§ØªÙŠØ©)
- âœ… **Marriage Package**: Complete all marriage-related procedures
- âœ… **Car Purchase Package**: Vehicle registration, insurance, license
- âœ… **Step-by-Step Progress**: Visual progress tracking

### ğŸ” Smart Search (Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ)
- âœ… **Service Discovery**: Find government services quickly
- âœ… **Natural Language**: Search in Arabic naturally
- âœ… **Auto-Complete**: Smart suggestions

### ğŸ¨ Modern UI/UX
- âœ… **Professional Design**: Dark green theme (#00663D)
- âœ… **RTL Support**: Full right-to-left layout
- âœ… **Responsive**: Works on all devices
- âœ… **Accessibility**: WCAG compliant
- âœ… **Smooth Animations**: Beautiful hover effects

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework**: Next.js 15 (React 19)
- **Language**: TypeScript 5
- **Styling**: Tailwind CSS
- **Icons**: Lucide React
- **Fonts**: Cairo, Tajawal (Arabic optimized)

### Backend
- **Framework**: FastAPI (Python)
- **Database**: SQLModel + PostgreSQL
- **Authentication**: JWT + bcrypt
- **API**: RESTful

### AI Services
- **LLM**: Groq (LLaMA 3.3 70B)
- **TTS**: ElevenLabs (Multilingual v2)
- **STT**: OpenAI Whisper
- **Voice ID**: `3nav5pHC1EYvWOd5LmnA`

### DevOps
- **Version Control**: Git
- **Package Manager**: npm/pnpm
- **Environment**: Node.js 18+, Python 3.11+

---

## ğŸ“ Project Structure

```
Absher-Kackathon/
â”œâ”€â”€ front-end/
â”‚   â””â”€â”€ clone-website-ui/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ api/
â”‚       â”‚   â”‚   â”œâ”€â”€ chat/          # AI chat endpoint
â”‚       â”‚   â”‚   â”œâ”€â”€ tts/           # Text-to-Speech
â”‚       â”‚   â”‚   â”œâ”€â”€ voice/         # Speech-to-Text
â”‚       â”‚   â”‚   â””â”€â”€ test-tts/      # TTS testing
â”‚       â”‚   â”œâ”€â”€ page.tsx           # Main page
â”‚       â”‚   â””â”€â”€ globals.css        # Global styles
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ AounChat.tsx       # Chat interface
â”‚       â”‚   â”œâ”€â”€ AounChatButton.tsx # Floating chat button
â”‚       â”‚   â”œâ”€â”€ VoiceCallPanel.tsx # Voice agent UI
â”‚       â”‚   â”œâ”€â”€ VoiceCallButton.tsx# Floating voice button
â”‚       â”‚   â”œâ”€â”€ LifeEventBundles.tsx
â”‚       â”‚   â”œâ”€â”€ header.tsx
â”‚       â”‚   â”œâ”€â”€ footer.tsx
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â””â”€â”€ speak.ts           # TTS utilities
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â”œâ”€â”€ violations.json
â”‚       â”‚   â”œâ”€â”€ profile.json
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ public/
â”‚           â”œâ”€â”€ absher-logo.svg
â”‚           â”œâ”€â”€ moi-2030-logos.png
â”‚           â””â”€â”€ test-tts.html      # TTS testing page
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                    # FastAPI app
â”‚   â”œâ”€â”€ models.py                  # Database models
â”‚   â”œâ”€â”€ api/                       # API routes
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸš€ Installation

### Prerequisites
- Node.js 18+ 
- Python 3.11+
- npm or pnpm
- Git

### 1ï¸âƒ£ Clone the Repository
```bash
git clone <repository-url>
cd Absher-Kackathon
```

### 2ï¸âƒ£ Backend Setup
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

### 3ï¸âƒ£ Frontend Setup
```bash
cd front-end/clone-website-ui
npm install
# or
pnpm install
```

### 4ï¸âƒ£ Environment Variables
Create `.env.local` in `front-end/clone-website-ui/`:

```env
GROQ_API_KEY=your_groq_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
OPENAI_API_KEY=your_openai_api_key
NEXT_PUBLIC_APP_URL=http://localhost:3000
```

---

## ğŸ”‘ Environment Variables

### Required API Keys

#### 1. **Groq API Key**
- Get from: [https://console.groq.com](https://console.groq.com)
- Model: `llama-3.3-70b-versatile`
- Usage: AI chat responses

#### 2. **ElevenLabs API Key**
- Get from: [https://elevenlabs.io](https://elevenlabs.io)
- Voice ID: `3nav5pHC1EYvWOd5LmnA`
- Model: `eleven_multilingual_v2`
- Usage: Text-to-Speech (Arabic)

#### 3. **OpenAI API Key**
- Get from: [https://platform.openai.com](https://platform.openai.com)
- Model: `whisper-1`
- Usage: Speech-to-Text (Arabic)

---

## ğŸ’» Usage

### Start Backend (Terminal 1)
```bash
cd backend
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```
Backend will run on: `http://localhost:8000`

### Start Frontend (Terminal 2)
```bash
cd front-end/clone-website-ui
npm run dev
```
Frontend will run on: `http://localhost:3000`

### Access the Application
- **Main App**: [http://localhost:3000](http://localhost:3000)
- **TTS Test Page**: [http://localhost:3000/test-tts.html](http://localhost:3000/test-tts.html)
- **API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ¤ Voice Agent

### How It Works

```mermaid
graph LR
    A[User Speaks] --> B[VAD Detects Speech]
    B --> C[Record Audio]
    C --> D[Silence Detected]
    D --> E[STT Whisper]
    E --> F[AI Processing]
    F --> G[TTS ElevenLabs]
    G --> H[Play Response]
    H --> A
```

### Configuration

#### Voice Activity Detection (VAD)
```typescript
{
  fftSize: 2048,
  smoothingTimeConstant: 0.8,
  voiceThreshold: 5,
  silenceDuration: 1000,  // 1 second
  maxRecordingTime: 6000  // 6 seconds
}
```

#### Audio Settings
```typescript
{
  echoCancellation: true,
  noiseSuppression: true,
  autoGainControl: true,
  sampleRate: 48000,
  channelCount: 1
}
```

#### TTS Settings
```json
{
  "voice_id": "3nav5pHC1EYvWOd5LmnA",
  "model_id": "eleven_multilingual_v2",
  "voice_settings": {
    "stability": 0.5,
    "similarity_boost": 0.75,
    "speed": 1.2
  }
}
```

---

## ğŸ“¡ API Documentation

### Chat Endpoint
```http
POST /api/chat
Content-Type: application/json

{
  "message": "Ù…Ø§ Ù‡ÙŠ Ù…Ø®Ø§Ù„ÙØ§ØªÙŠØŸ",
  "conversationHistory": []
}
```

### TTS Endpoint
```http
POST /api/tts
Content-Type: application/json

{
  "text": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø£Ø¨Ø´Ø±"
}
```

### STT Endpoint
```http
POST /api/voice
Content-Type: multipart/form-data

audio: <audio-file.webm>
```

---

## ğŸ› Debugging

### Enable Detailed Logs

The voice agent includes comprehensive logging:

```javascript
// Open Browser Console (F12)
// You'll see logs like:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¬ [VoiceCall] Component mounted
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”Š [speakArabic] Starting playback...
âœ… [speakArabic] Playback started
â–¶ï¸ [Recording] startRecording() called
ğŸ¤ [Recording] Current isSpeaking: false
âœ… [Recording] MediaRecorder started
ğŸ“ [STT] Transcription successful
ğŸ¤– [AI] Getting AI response
ğŸ’¬ [AI] Response: Ù„Ø¯ÙŠÙƒ 3 Ù…Ø®Ø§Ù„ÙØ§Øª...
```

### Testing TTS
Visit: `http://localhost:3000/test-tts.html`

---

## ğŸ¨ Design System

### Colors
- **Primary**: `#00663D` (Dark Green)
- **Primary Light**: `#008850`
- **Primary Dark**: `#004A2C`
- **Surface**: `#F7F7F7`
- **Border**: `#E4E4E7`
- **Error**: `#DC2626`

### Typography
- **Arabic Font**: Cairo, Tajawal
- **Sizes**: 
  - Headers: `text-xl` to `text-2xl` (20px-24px)
  - Body: `text-base` (16px)
  - Small: `text-sm` (14px)

### Spacing
- **Base**: 4px (0.25rem)
- **Components**: 16px-24px (1rem-1.5rem)
- **Sections**: 32px-48px (2rem-3rem)

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style
- Use TypeScript for frontend
- Follow ESLint rules
- Use Prettier for formatting
- Write meaningful commit messages
- Add comments for complex logic

---

## ğŸ“ License

This project was developed for the Saudi Arabian Absher Hackathon.

---

## ğŸ‘¥ Team

Developed with â¤ï¸ for the Ministry of Interior - Kingdom of Saudi Arabia

---

## ğŸ“ Contact & Support

For issues, questions, or support:
- Open an issue on GitHub
- Contact the development team

---

## ğŸ™ Acknowledgments

- **Ministry of Interior** - For the Absher platform
- **Vision 2030** - For digital transformation initiatives
- **Groq** - For AI inference
- **ElevenLabs** - For TTS services
- **OpenAI** - For Whisper STT

---

<div align="center">

**Made with â¤ï¸ for Saudi Arabia ğŸ‡¸ğŸ‡¦**

</div>
